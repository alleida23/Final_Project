{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24740cc2",
   "metadata": {},
   "source": [
    "## Predicting Book Ratings on GoodReads using Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062220f2",
   "metadata": {},
   "source": [
    "The objective of this section is to develop a linear regression model to forecast the \"rating\" value of books from GoodReads.\n",
    "\n",
    "To achieve this goal, amongst other typical variables to rate literary books, I will use the \"genres\" and \"awards\" attributes, which were initially present in the dataset as strings embedded in individual lists. These two features contained up to 980 unique genres and 5831 unique awards.\n",
    "\n",
    "After extracting, transforming, and reducing them into numerical variables in previous steps, I expect them to be sufficiently related to the target and that will enhance the robustness of the model.\n",
    "\n",
    "The following steps will be undertaken in this process:\n",
    "\n",
    "- Import the cleaned dataframe.\n",
    "- Preprocess the variables to select and modify the appropriate ones for modeling.\n",
    "- Develop the linear regression model and evaluate the performance metrics.\n",
    "- Incorporate enhancements, if possible, such as using dimensionality reduction.\n",
    "- Compare the outcomes with those of another regression model, Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d3aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f9aa9",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd042c",
   "metadata": {},
   "source": [
    "Importing clean dataframe\n",
    "- Cleaning and wrangling were done in \"1. goodreads_data_CLEANING_AND_WRANGLING.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01df9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_data = pd.read_csv('./2. Clean_df/gr_data_CLEAN.csv')\n",
    "gr_data = gr_data.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e836f677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_format</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>first_publish_year</th>\n",
       "      <th>...</th>\n",
       "      <th>West Australian Young Readers' Book Award (WAYRBA) for Older Readers</th>\n",
       "      <th>West Australian Young Readers' Book Award (WAYRBA) for Younger Readers</th>\n",
       "      <th>William Allen White Children's Book Award</th>\n",
       "      <th>William C. Morris YA Debut Award Nominee</th>\n",
       "      <th>Women's Prize for Fiction Nominee</th>\n",
       "      <th>Women's Prize for Fiction Nominee for Longlist</th>\n",
       "      <th>World Fantasy Award Nominee for Best Novel</th>\n",
       "      <th>World Fantasy Award for Best Novel</th>\n",
       "      <th>Zilveren Griffel</th>\n",
       "      <th>الجائزة العالمية للرواية العربية (أي باف) / International Prize for Arabic Fiction (IPAF) Nominee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>700-800</td>\n",
       "      <td>9.78044E+12</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>2004</td>\n",
       "      <td>2003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>1E+13</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>2006</td>\n",
       "      <td>1960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>English</td>\n",
       "      <td>100-200</td>\n",
       "      <td>1E+13</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>English</td>\n",
       "      <td>400-500</td>\n",
       "      <td>9.78032E+12</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>2006</td>\n",
       "      <td>2005</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title                 series  \\\n",
       "0                           The Hunger Games       The Hunger Games   \n",
       "1  Harry Potter and the Order of the Phoenix           Harry Potter   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice            Single Book   \n",
       "4                                   Twilight      The Twilight Saga   \n",
       "\n",
       "            author                                        description  \\\n",
       "0  Suzanne Collins  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...   \n",
       "1     J.K. Rowling  There is a door at the end of a silent corrido...   \n",
       "2       Harper Lee  The unforgettable novel of a childhood in a sl...   \n",
       "3      Jane Austen  Alternate cover edition of ISBN 9780679783268S...   \n",
       "4  Stephenie Meyer  About three things I was absolutely positive.\\...   \n",
       "\n",
       "  language    pages         isbn book_format  publish_year  \\\n",
       "0  English  200-300  9.78044E+12   Hardcover          2008   \n",
       "1  English  700-800  9.78044E+12   Paperback          2004   \n",
       "2  English  200-300        1E+13   Paperback          2006   \n",
       "3  English  100-200        1E+13   Paperback          2000   \n",
       "4  English  400-500  9.78032E+12   Paperback          2006   \n",
       "\n",
       "   first_publish_year  ...  \\\n",
       "0                2008  ...   \n",
       "1                2003  ...   \n",
       "2                1960  ...   \n",
       "3                2013  ...   \n",
       "4                2005  ...   \n",
       "\n",
       "  West Australian Young Readers' Book Award (WAYRBA) for Older Readers   \\\n",
       "0                                                  1                      \n",
       "1                                                  0                      \n",
       "2                                                  0                      \n",
       "3                                                  0                      \n",
       "4                                                  1                      \n",
       "\n",
       "   West Australian Young Readers' Book Award (WAYRBA) for Younger Readers   \\\n",
       "0                                                  0                         \n",
       "1                                                  0                         \n",
       "2                                                  0                         \n",
       "3                                                  0                         \n",
       "4                                                  0                         \n",
       "\n",
       "   William Allen White Children's Book Award   \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   William C. Morris YA Debut Award Nominee   \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   Women's Prize for Fiction Nominee   \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "\n",
       "   Women's Prize for Fiction Nominee for Longlist   \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   World Fantasy Award Nominee for Best Novel   \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   World Fantasy Award for Best Novel   Zilveren Griffel   \\\n",
       "0                                    0                  0   \n",
       "1                                    0                  0   \n",
       "2                                    0                  0   \n",
       "3                                    0                  0   \n",
       "4                                    0                  0   \n",
       "\n",
       "   الجائزة العالمية للرواية العربية (أي باف) / International Prize for Arabic Fiction (IPAF) Nominee   \n",
       "0                                                  0                                                   \n",
       "1                                                  0                                                   \n",
       "2                                                  0                                                   \n",
       "3                                                  0                                                   \n",
       "4                                                  0                                                   \n",
       "\n",
       "[5 rows x 862 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(48655, 862)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(gr_data.head(), gr_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a66ef6",
   "metadata": {},
   "source": [
    "### Preprocessing data and features for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781a6eb",
   "metadata": {},
   "source": [
    "#### Drop unnecesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df632d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_data= gr_data.drop(['isbn','description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758dffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 860)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db57dc",
   "metadata": {},
   "source": [
    "#### NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2bbd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11829a3a",
   "metadata": {},
   "source": [
    "#### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce4c1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                   object\n",
       "series                  object\n",
       "author                  object\n",
       "language                object\n",
       "pages                   object\n",
       "book_format             object\n",
       "publish_year             int64\n",
       "first_publish_year       int64\n",
       "publisher               object\n",
       "liked_perc             float64\n",
       "bbe_score              float64\n",
       "bbe_votes              float64\n",
       "log_num_ratings        float64\n",
       "5_stars_num_ratings      int64\n",
       "4_stars_num_ratings      int64\n",
       "3_stars_num_ratings      int64\n",
       "2_stars_num_ratings      int64\n",
       "1_star_num_ratings       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data.iloc[:, :18].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f46d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: 853\n",
      "Categorical columns: 7\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = gr_data.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Numerical columns: {len(numerical_columns)}\")\n",
    "\n",
    "categorical_columns = gr_data.select_dtypes(include='object').columns.tolist()\n",
    "print(f\"Categorical columns: {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100aa9c",
   "metadata": {},
   "source": [
    "#### Dealing with type of 'genres' and 'awards' multiple columns.\n",
    "#### Converting to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b90317",
   "metadata": {},
   "source": [
    "After extracting their names from their respective lists, I created two dataframes in which each unique genre and award was converted into a single column. If the original list for a book (row) contained that genre or award, the corresponding value in that record was assigned a 1; otherwise, it was assigned a 0.\n",
    "\n",
    "The only exceptions are the columns that hold aggregated numbers for the binned awards in 'Unique Award (1)', 'Uncommon Award (2,3)', 'Singular Award (4-8)', and 'Frequently Awarded Literary Prizes (9-15)'. In order to reduce the thousands of unique awards, I grouped them according to their frequency.\n",
    "\n",
    "Since the binned award columns should be treated as numerical data and the 1-0 column values as categorical, I will import those dataframes to generate a list with all those columns names (more than 800) and then assign the appropriate data types in the original dataframe.\n",
    "\n",
    "Kernels (in '0. Drafts' folder):\n",
    "\n",
    "- 1.1 goodreads_genres_REDUCTION.ipynb\n",
    "- 1.2 goodreads_genres_NEWDF.ipynb\n",
    "- 1.3 goodreads_awards_NEWDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b99570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataframes\n",
    "award_df = pd.read_csv('./0. Drafts/award_df.csv')\n",
    "award_df = award_df.drop(['Unnamed: 0'],axis=1)\n",
    "award_df = award_df.drop(['index_gr_data'],axis=1)\n",
    "\n",
    "genres_df = pd.read_csv('./0. Drafts/genres_clean_dataset.csv')\n",
    "genres_df = genres_df.drop(['Unnamed: 0'],axis=1)\n",
    "genres_df = genres_df.drop(['index_gr_data'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b602f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As all values in genre_df are 0 or 1, I'm appending them into binary_columns list\n",
    "binary_columns = [column for column in genres_df.columns]\n",
    "len(binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c449b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting binary column names and appending to previous list.\n",
    "for column in award_df.columns:\n",
    "    unique_values = award_df[column].unique()\n",
    "    if set(unique_values) != set([0, 1]):\n",
    "        continue\n",
    "        #non_binary_columns.append(column)\n",
    "    elif set(unique_values) == set([0, 1]):\n",
    "        binary_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5d7c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New length\n",
    "len(binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a0d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through columns names in gr_data; if listed in binary_columns converted to 'object' type\n",
    "for column in gr_data.columns:\n",
    "    if column in binary_columns:\n",
    "        gr_data[column] = gr_data[column].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d4527c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: 16\n",
      "Categorical columns: 844\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = gr_data.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"Numerical columns: {len(numerical_columns)}\")\n",
    "\n",
    "categorical_columns = gr_data.select_dtypes(include='object').columns.tolist()\n",
    "print(f\"Categorical columns: {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7aeb94",
   "metadata": {},
   "source": [
    "#### Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e24e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = gr_data.select_dtypes(include=np.number)\n",
    "numerical.shape\n",
    "#categorical = gr_data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280b3bc",
   "metadata": {},
   "source": [
    "- Correlation amongst features: correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12272a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical values (854 columns)\n",
    "corr_matrix = numerical.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "063879d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row name</th>\n",
       "      <th>col name</th>\n",
       "      <th>corr number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3_stars_num_ratings</td>\n",
       "      <td>4_stars_num_ratings</td>\n",
       "      <td>0.957836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2_stars_num_ratings</td>\n",
       "      <td>3_stars_num_ratings</td>\n",
       "      <td>0.956072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bbe_score</td>\n",
       "      <td>bbe_votes</td>\n",
       "      <td>0.939596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1_star_num_ratings</td>\n",
       "      <td>2_stars_num_ratings</td>\n",
       "      <td>0.933824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4_stars_num_ratings</td>\n",
       "      <td>5_stars_num_ratings</td>\n",
       "      <td>0.931859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2_stars_num_ratings</td>\n",
       "      <td>4_stars_num_ratings</td>\n",
       "      <td>0.856281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3_stars_num_ratings</td>\n",
       "      <td>5_stars_num_ratings</td>\n",
       "      <td>0.831870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1_star_num_ratings</td>\n",
       "      <td>3_stars_num_ratings</td>\n",
       "      <td>0.820076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2_stars_num_ratings</td>\n",
       "      <td>5_stars_num_ratings</td>\n",
       "      <td>0.726403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_star_num_ratings</td>\n",
       "      <td>4_stars_num_ratings</td>\n",
       "      <td>0.711987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1_star_num_ratings</td>\n",
       "      <td>5_stars_num_ratings</td>\n",
       "      <td>0.639672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               row name             col name  corr number\n",
       "11  3_stars_num_ratings  4_stars_num_ratings     0.957836\n",
       "16  2_stars_num_ratings  3_stars_num_ratings     0.956072\n",
       "0             bbe_score            bbe_votes     0.939596\n",
       "21   1_star_num_ratings  2_stars_num_ratings     0.933824\n",
       "6   4_stars_num_ratings  5_stars_num_ratings     0.931859\n",
       "15  2_stars_num_ratings  4_stars_num_ratings     0.856281\n",
       "10  3_stars_num_ratings  5_stars_num_ratings     0.831870\n",
       "20   1_star_num_ratings  3_stars_num_ratings     0.820076\n",
       "14  2_stars_num_ratings  5_stars_num_ratings     0.726403\n",
       "19   1_star_num_ratings  4_stars_num_ratings     0.711987\n",
       "18   1_star_num_ratings  5_stars_num_ratings     0.639672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Indices of non-NaN values in the correlation matrix\n",
    "indices = [(row, col) for row in corr_matrix.index for col in corr_matrix.columns if not pd.isna(corr_matrix.loc[row, col])]\n",
    "\n",
    "# New df with the row and column's names, and correlation number\n",
    "df = pd.DataFrame([(idx[0], idx[1], corr_matrix.loc[idx]) for idx in indices if (corr_matrix.loc[idx] > 0.6 or corr_matrix.loc[idx] < -0.6) and idx[0] != idx[1]], columns=['row name', 'col name', 'corr number'])\n",
    "\n",
    "# Drop duplicate rows where row name is greater than col name (diagonal)\n",
    "df = df[df['row name'] < df['col name']]\n",
    "\n",
    "# Sort df by the correlation number in descending order\n",
    "df = df.sort_values(by='corr number', ascending=False)\n",
    "\n",
    "# Sorted df\n",
    "display(df, len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ae65b",
   "metadata": {},
   "source": [
    " - Check counts from paired highly-correlated variables to choose which one to eliminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa848682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(numerical['Hugo Award for Best Novel '].value_counts(),numerical['hugo awards'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927103e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(numerical['love inspired'].value_counts(),numerical['love inspired historical'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a4a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High correlated variables to drop\n",
    "high_correlated = ['2_stars_num_ratings','3_stars_num_ratings','4_stars_num_ratings',\n",
    "                   'bbe_votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d1bc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High correlated variables to drop\n",
    "# high_correlated = ['2_stars_num_ratings','3_stars_num_ratings','4_stars_num_ratings',\n",
    "#                   'bbe_votes','hugo awards','booze','love inspired historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b669b25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bbe0bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop high correlated variables\n",
    "numerical = numerical.drop(high_correlated, axis=1)\n",
    "\n",
    "# New shape\n",
    "numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d4559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ebd3c4",
   "metadata": {},
   "source": [
    "#### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11cac4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 844)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = gr_data.select_dtypes(include=['object'])\n",
    "categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa4635b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values\n",
    "#for col in categorical.columns:\n",
    "#    print(f\"Unique values for {col}: {categorical[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6190c",
   "metadata": {},
   "source": [
    "- Reducing unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d338d2",
   "metadata": {},
   "source": [
    "Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e93911a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Suzanne Collins\n",
       "1           J.K. Rowling\n",
       "2             Harper Lee\n",
       "3            Jane Austen\n",
       "4        Stephenie Meyer\n",
       "              ...       \n",
       "48650      Sherry Gammon\n",
       "48651      Emma Michaels\n",
       "48652     Kim Richardson\n",
       "48653        Tom Pollack\n",
       "48654       Misty Moncur\n",
       "Name: author, Length: 48655, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b7af5",
   "metadata": {},
   "source": [
    "To categorize the authors, I will group them into 'Top 1000', 'Top 1001-10000', and 'General Authors'. This grouping will be based on the average 'rating' of authors who have published more than one book.\n",
    "\n",
    "To ensure a fair average, I will exclude authors who have only published one book and received a rating of 5 from the calculation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee01ef31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Goodman</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug \"Hollywood\" Davis</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natasha Lukin</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rita Pam Tarachi</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Granthana Sinha</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadine May</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bernard Cenney</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Luke A.M. Brown</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Susan Davis</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rodolfo Martin Vitangcol</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Jones Snr</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carol Denise Mitchell</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crystal L. Du Bois</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cristina G.</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Creative Success Coach</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cat Ellington</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Melissa Webb</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Silvana G. Sánchez</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Martine Jardin</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lisa C. Miller</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jerrye Woods</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lashone Vs Shaneek</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Garry Bonsall</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Violet Plum</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Alice Batchelor Hambright</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Vidya Gargote</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ginger Baum</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sharon Storm</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Anişoara Laura Musteţiu</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Krystyna Fitzgerald-Morris</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        author  rating\n",
       "0                James Goodman    5.00\n",
       "1       Doug \"Hollywood\" Davis    5.00\n",
       "2                Natasha Lukin    5.00\n",
       "3             Rita Pam Tarachi    5.00\n",
       "4              Granthana Sinha    5.00\n",
       "5                   Nadine May    5.00\n",
       "6               Bernard Cenney    5.00\n",
       "7              Luke A.M. Brown    5.00\n",
       "8                  Susan Davis    5.00\n",
       "9     Rodolfo Martin Vitangcol    5.00\n",
       "10             Steve Jones Snr    5.00\n",
       "11       Carol Denise Mitchell    5.00\n",
       "12          Crystal L. Du Bois    5.00\n",
       "13                 Cristina G.    5.00\n",
       "14      Creative Success Coach    5.00\n",
       "15               Cat Ellington    5.00\n",
       "16                Melissa Webb    5.00\n",
       "17          Silvana G. Sánchez    5.00\n",
       "18              Martine Jardin    5.00\n",
       "19              Lisa C. Miller    5.00\n",
       "20                Jerrye Woods    5.00\n",
       "21          Lashone Vs Shaneek    5.00\n",
       "22               Garry Bonsall    5.00\n",
       "23                 Violet Plum    5.00\n",
       "24   Alice Batchelor Hambright    5.00\n",
       "25               Vidya Gargote    5.00\n",
       "26                 Ginger Baum    4.97\n",
       "27                Sharon Storm    4.96\n",
       "28     Anişoara Laura Musteţiu    4.96\n",
       "29  Krystyna Fitzgerald-Morris    4.95"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of books for each author\n",
    "author_counts = gr_data['author'].value_counts()\n",
    "\n",
    "# Filter to only include authors with a count greater than 1\n",
    "filtered_authors = author_counts[author_counts > 1].index\n",
    "\n",
    "# Filter in the original df to only include titles with authors in the filtered authors\n",
    "filtered_gr_data = gr_data[gr_data['author'].isin(filtered_authors)]\n",
    "\n",
    "# Group by author and calculate the mean rating for each author\n",
    "author_avg_rating = filtered_gr_data.groupby('author')['rating'].mean()\n",
    "\n",
    "# Sort in descending order of average rating and select the top 1000 authors\n",
    "top_1000_most_rated_authors = author_avg_rating.sort_values(ascending=False).head(1000)\n",
    "\n",
    "# Convert to a dataframe\n",
    "top_1000_most_rated_authors_df = top_1000_most_rated_authors.to_frame().reset_index()\n",
    "\n",
    "display(len(top_1000_most_rated_authors_df))\n",
    "\n",
    "top_1000_most_rated_authors_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09d7272e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrienne Rich</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E.F. Benson</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexie Xu</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anna Zaires</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mandi Beck</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arnold Lobel</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lois Walfrid Johnson</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amy Clipston</td>\n",
       "      <td>4.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.M. Darhower</td>\n",
       "      <td>4.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mike Mignola</td>\n",
       "      <td>4.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Miasha</td>\n",
       "      <td>4.275714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jon J. Muth</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V.D. Savarkar</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E.J. Mellow</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Juan Díaz Canales</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wallace D. Wattles</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shinobu Kaitani</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bisco Hatori</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mahmoud Darwish</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Elena Garro</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Matthew Van Fleet</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dale Cramer</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Gilbert Hernández</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Krishna-Dwaipayana Vyasa</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Luis Buñuel</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kyle Idleman</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eric Wilson</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Michelle Sutton</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Angelina J. Steffort</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jillian Dodd</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      author    rating\n",
       "0              Adrienne Rich  4.276667\n",
       "1                E.F. Benson  4.276667\n",
       "2                   Lexie Xu  4.276667\n",
       "3                Anna Zaires  4.276667\n",
       "4                 Mandi Beck  4.276667\n",
       "5               Arnold Lobel  4.276667\n",
       "6       Lois Walfrid Johnson  4.276667\n",
       "7               Amy Clipston  4.276667\n",
       "8              J.M. Darhower  4.276000\n",
       "9               Mike Mignola  4.276000\n",
       "10                    Miasha  4.275714\n",
       "11               Jon J. Muth  4.275000\n",
       "12             V.D. Savarkar  4.275000\n",
       "13               E.J. Mellow  4.275000\n",
       "14         Juan Díaz Canales  4.275000\n",
       "15        Wallace D. Wattles  4.275000\n",
       "16           Shinobu Kaitani  4.275000\n",
       "17              Bisco Hatori  4.275000\n",
       "18           Mahmoud Darwish  4.275000\n",
       "19               Elena Garro  4.275000\n",
       "20         Matthew Van Fleet  4.275000\n",
       "21               Dale Cramer  4.275000\n",
       "22         Gilbert Hernández  4.275000\n",
       "23  Krishna-Dwaipayana Vyasa  4.275000\n",
       "24               Luis Buñuel  4.275000\n",
       "25              Kyle Idleman  4.275000\n",
       "26               Eric Wilson  4.275000\n",
       "27           Michelle Sutton  4.275000\n",
       "28      Angelina J. Steffort  4.274000\n",
       "29              Jillian Dodd  4.274000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second group, same process\n",
    "\n",
    "author_counts = gr_data['author'].value_counts()\n",
    "filtered_authors = author_counts[author_counts > 1].index\n",
    "filtered_gr_data = gr_data[gr_data['author'].isin(filtered_authors)]\n",
    "author_avg_rating = filtered_gr_data.groupby('author')['rating'].mean()\n",
    "top_1001_to_10000_most_rated_authors = author_avg_rating.sort_values(ascending=False).iloc[1000:10000]\n",
    "top_1001_to_10000_most_rated_authors_df = top_1001_to_10000_most_rated_authors.to_frame().reset_index()\n",
    "\n",
    "display(len(top_1001_to_10000_most_rated_authors_df))\n",
    "top_1001_to_10000_most_rated_authors_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33ef7ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50 Cent</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Bates</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Cort Sinnes</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Helwa</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Merritt</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A. Roger Ekirch</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A. Scott Berg</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A. Teeuw</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A. Ubaidillah Alias</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A. White</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A.C. Bhaktivedanta Swami Prabhupāda</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A.C. Weisbecker</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A.C.H. Smith</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A.D. Bloom</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A.D. Truax</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A.D.T. McLellan</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A.F. Harrold</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.F. Knott</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A.G. Cairns-Smith</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A.G. Mogan</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A.G. Roemmers</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A.H. Anquetil-Duperron</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A.J. Betts</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A.J. Finn</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A.J. Forrest</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A.J. Hackwith</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A.J. Jacobs</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A.J. Kazinski</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A.J. Mackinnon</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A.J. Mendez Brooks</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 author  rating\n",
       "0                               50 Cent    4.15\n",
       "1                              A. Bates    3.54\n",
       "2                        A. Cort Sinnes    4.50\n",
       "3                              A. Helwa    4.63\n",
       "4                            A. Merritt    3.33\n",
       "5                       A. Roger Ekirch    3.68\n",
       "6                         A. Scott Berg    4.00\n",
       "7                              A. Teeuw    4.06\n",
       "8                   A. Ubaidillah Alias    3.94\n",
       "9                              A. White    4.93\n",
       "10  A.C. Bhaktivedanta Swami Prabhupāda    4.54\n",
       "11                      A.C. Weisbecker    3.88\n",
       "12                         A.C.H. Smith    4.20\n",
       "13                           A.D. Bloom    3.87\n",
       "14                           A.D. Truax    4.02\n",
       "15                      A.D.T. McLellan    4.51\n",
       "16                         A.F. Harrold    4.03\n",
       "17                           A.F. Knott    4.50\n",
       "18                    A.G. Cairns-Smith    4.02\n",
       "19                           A.G. Mogan    4.25\n",
       "20                        A.G. Roemmers    3.38\n",
       "21               A.H. Anquetil-Duperron    5.00\n",
       "22                           A.J. Betts    3.68\n",
       "23                            A.J. Finn    3.94\n",
       "24                         A.J. Forrest    4.00\n",
       "25                        A.J. Hackwith    3.85\n",
       "26                          A.J. Jacobs    3.75\n",
       "27                        A.J. Kazinski    3.53\n",
       "28                       A.J. Mackinnon    4.26\n",
       "29                   A.J. Mendez Brooks    4.49"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third group, same process\n",
    "\n",
    "author_counts = gr_data['author'].value_counts()\n",
    "single_authors = author_counts[author_counts == 1].index\n",
    "general_authors_data = gr_data[~gr_data['author'].isin(top_1000_most_rated_authors.index) & ~gr_data['author'].isin(top_1000_most_rated_authors.index) & gr_data['author'].isin(single_authors)]\n",
    "general_authors_avg_rating = general_authors_data.groupby('author')['rating'].mean()\n",
    "general_authors_avg_rating_df = general_authors_avg_rating.to_frame().reset_index()\n",
    "\n",
    "display(len(general_authors_avg_rating_df))\n",
    "general_authors_avg_rating_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "844c136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique authors in the three new dataframes is equal to the number of unique authors in the original gr_data dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Check result\n",
    "\n",
    "# Unique authors in the original dataframe\n",
    "num_unique_authors = len(gr_data['author'].unique())\n",
    "\n",
    "# Unique authors in new authors dataframes\n",
    "num_top_1000_authors = len(top_1000_most_rated_authors_df)\n",
    "num_top_1001_to_10000_authors = len(top_1001_to_10000_most_rated_authors_df)\n",
    "num_general_authors = len(general_authors_avg_rating_df)\n",
    "\n",
    "# Check if the sum of the number of new dataframes is equal to unique authors in the original dataframe\n",
    "if num_top_1000_authors + num_top_1001_to_10000_authors + num_general_authors == num_unique_authors:\n",
    "    print(\"The number of unique authors in the three new dataframes is equal to the number of unique authors in the original gr_data dataframe.\")\n",
    "else:\n",
    "    print(\"The number of unique authors in the three new dataframes is not equal to the number of unique authors in the original gr_data dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6797c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>book_format</th>\n",
       "      <th>publisher</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>science fiction</th>\n",
       "      <th>dystopia</th>\n",
       "      <th>...</th>\n",
       "      <th>West Australian Young Readers' Book Award (WAYRBA) for Older Readers</th>\n",
       "      <th>West Australian Young Readers' Book Award (WAYRBA) for Younger Readers</th>\n",
       "      <th>William Allen White Children's Book Award</th>\n",
       "      <th>William C. Morris YA Debut Award Nominee</th>\n",
       "      <th>Women's Prize for Fiction Nominee</th>\n",
       "      <th>Women's Prize for Fiction Nominee for Longlist</th>\n",
       "      <th>World Fantasy Award Nominee for Best Novel</th>\n",
       "      <th>World Fantasy Award for Best Novel</th>\n",
       "      <th>Zilveren Griffel</th>\n",
       "      <th>الجائزة العالمية للرواية العربية (أي باف) / International Prize for Arabic Fiction (IPAF) Nominee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter</td>\n",
       "      <td>top_1000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>700-800</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>100-200</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>400-500</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>400-500</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Chronicles of Narnia</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>600-700</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>The Lord of the Rings-3</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>900-1000</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>900-1000</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 844 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                   series  \\\n",
       "0                                   The Hunger Games         The Hunger Games   \n",
       "1          Harry Potter and the Order of the Phoenix             Harry Potter   \n",
       "2                              To Kill a Mockingbird    To Kill a Mockingbird   \n",
       "3                                Pride and Prejudice              Single Book   \n",
       "4                                           Twilight        The Twilight Saga   \n",
       "5                                     The Book Thief              Single Book   \n",
       "6                                        Animal Farm              Single Book   \n",
       "7                           The Chronicles of Narnia              Single Book   \n",
       "8  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...  The Lord of the Rings-3   \n",
       "9                                 Gone with the Wind              Single Book   \n",
       "\n",
       "                                 author language     pages book_format  \\\n",
       "0  top_1001_to_10000_most_rated_authors  English   200-300   Hardcover   \n",
       "1           top_1000_most_rated_authors  English   700-800   Paperback   \n",
       "2  top_1001_to_10000_most_rated_authors  English   200-300   Paperback   \n",
       "3  top_1001_to_10000_most_rated_authors  English   100-200   Paperback   \n",
       "4  top_1001_to_10000_most_rated_authors  English   400-500   Paperback   \n",
       "5  top_1001_to_10000_most_rated_authors  English   400-500   Hardcover   \n",
       "6  top_1001_to_10000_most_rated_authors  English      <100   Paperback   \n",
       "7  top_1001_to_10000_most_rated_authors  English   600-700   Paperback   \n",
       "8  top_1001_to_10000_most_rated_authors  English  900-1000   Paperback   \n",
       "9           top_1000_most_rated_authors  English  900-1000   Paperback   \n",
       "\n",
       "        publisher fantasy science fiction dystopia  ...  \\\n",
       "0  Top Publishers       1               1        1  ...   \n",
       "1  Top Publishers       1               1        0  ...   \n",
       "2  Top Publishers       0               0        0  ...   \n",
       "3  Top Publishers       0               0        0  ...   \n",
       "4  Top Publishers       1               1        0  ...   \n",
       "5  Top Publishers       0               0        0  ...   \n",
       "6  Top Publishers       1               1        1  ...   \n",
       "7  Top Publishers       1               1        0  ...   \n",
       "8  Top Publishers       1               1        0  ...   \n",
       "9  Top Publishers       0               0        0  ...   \n",
       "\n",
       "  West Australian Young Readers' Book Award (WAYRBA) for Older Readers   \\\n",
       "0                                                  1                      \n",
       "1                                                  0                      \n",
       "2                                                  0                      \n",
       "3                                                  0                      \n",
       "4                                                  1                      \n",
       "5                                                  0                      \n",
       "6                                                  0                      \n",
       "7                                                  0                      \n",
       "8                                                  0                      \n",
       "9                                                  0                      \n",
       "\n",
       "  West Australian Young Readers' Book Award (WAYRBA) for Younger Readers   \\\n",
       "0                                                  0                        \n",
       "1                                                  0                        \n",
       "2                                                  0                        \n",
       "3                                                  0                        \n",
       "4                                                  0                        \n",
       "5                                                  0                        \n",
       "6                                                  0                        \n",
       "7                                                  0                        \n",
       "8                                                  0                        \n",
       "9                                                  0                        \n",
       "\n",
       "  William Allen White Children's Book Award   \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "5                                          0   \n",
       "6                                          0   \n",
       "7                                          0   \n",
       "8                                          0   \n",
       "9                                          0   \n",
       "\n",
       "  William C. Morris YA Debut Award Nominee   \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "5                                         0   \n",
       "6                                         0   \n",
       "7                                         0   \n",
       "8                                         0   \n",
       "9                                         0   \n",
       "\n",
       "  Women's Prize for Fiction Nominee   \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "5                                  0   \n",
       "6                                  0   \n",
       "7                                  0   \n",
       "8                                  0   \n",
       "9                                  0   \n",
       "\n",
       "  Women's Prize for Fiction Nominee for Longlist   \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               0   \n",
       "8                                               0   \n",
       "9                                               0   \n",
       "\n",
       "  World Fantasy Award Nominee for Best Novel   \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "5                                           0   \n",
       "6                                           0   \n",
       "7                                           0   \n",
       "8                                           0   \n",
       "9                                           0   \n",
       "\n",
       "  World Fantasy Award for Best Novel  Zilveren Griffel   \\\n",
       "0                                   0                 0   \n",
       "1                                   0                 0   \n",
       "2                                   0                 0   \n",
       "3                                   0                 0   \n",
       "4                                   0                 0   \n",
       "5                                   0                 0   \n",
       "6                                   0                 0   \n",
       "7                                   0                 0   \n",
       "8                                   0                 0   \n",
       "9                                   0                 0   \n",
       "\n",
       "  الجائزة العالمية للرواية العربية (أي باف) / International Prize for Arabic Fiction (IPAF) Nominee   \n",
       "0                                                  0                                                  \n",
       "1                                                  0                                                  \n",
       "2                                                  0                                                  \n",
       "3                                                  0                                                  \n",
       "4                                                  0                                                  \n",
       "5                                                  0                                                  \n",
       "6                                                  0                                                  \n",
       "7                                                  0                                                  \n",
       "8                                                  0                                                  \n",
       "9                                                  0                                                  \n",
       "\n",
       "[10 rows x 844 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the author values in categorical['author'] with the appropriate category\n",
    "categorical['author'] = np.where(categorical['author'].isin(top_1000_most_rated_authors_df['author']), 'top_1000_most_rated_authors',\n",
    "                        np.where(categorical['author'].isin(top_1001_to_10000_most_rated_authors_df['author']), 'top_1001_to_10000_most_rated_authors',\n",
    "                        np.where(categorical['author'].isin(general_authors_avg_rating_df['author']), 'general_authors',\n",
    "                                 categorical['author'])))\n",
    "\n",
    "categorical.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "737ab798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['top_1001_to_10000_most_rated_authors',\n",
       "       'top_1000_most_rated_authors', 'general_authors'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['author'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045d8ae",
   "metadata": {},
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afde646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4405"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['series'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41632580",
   "metadata": {},
   "source": [
    "To group the series, I will create two categories: 'Top 500 rated series' and 'Other Series'. For books not included in any literary saga, I will keep them under the existing 'Single Books' category. The grouping will be based on the average 'rating' for each series, using a similar process to the previous grouping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb1e9752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original dataframe to only include titles that are not 'Single Book'\n",
    "series_data = gr_data[gr_data['series'] != 'Single Book']\n",
    "\n",
    "# Group by series and calculate the mean rating for each series\n",
    "series_avg_rating = series_data.groupby('series')['rating'].mean()\n",
    "\n",
    "# Sort in descending order based on the average rating and select the top 500 series\n",
    "top_500_most_rated_series = series_avg_rating.sort_values(ascending=False).head(500)\n",
    "\n",
    "# Filter the original dataframe to only include titles with series not in the top rated series lists or with empty series\n",
    "other_series_data = series_data[~series_data['series'].isin(top_500_most_rated_series.index) & (series_data['series'] != '')]\n",
    "\n",
    "# Group by series and calculate the mean rating for each series\n",
    "other_series_avg_rating = other_series_data.groupby('series')['rating'].mean()\n",
    "\n",
    "# Convert to a dataframe\n",
    "top_500_most_rated_series_df = top_500_most_rated_series.to_frame().reset_index()\n",
    "other_series_avg_rating_df = other_series_avg_rating.to_frame().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26948f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace series values in categorical['series'] with the appropriate category\n",
    "categorical['series'] = np.where(categorical['series'] == 'Single Book', 'Single Book',\n",
    "                    np.where(categorical['series'].isin(top_500_most_rated_series_df['series']), 'Top 500 rated series',\n",
    "                    np.where(categorical['series'].isin(other_series_avg_rating_df['series']), 'Other series',\n",
    "                    categorical['series'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "899c7ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other series', 'Top 500 rated series', 'Single Book'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['series'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d80d5c",
   "metadata": {},
   "source": [
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80ee0928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46328"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e8741",
   "metadata": {},
   "source": [
    "As there are a lot of unique authors, I have decided to drop that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3fdc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.drop(['title'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e836d3",
   "metadata": {},
   "source": [
    "Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b522f8b",
   "metadata": {},
   "source": [
    "Here, I will identify the 5 most frequently published languages and keep their names. For all other languages, I will group them into a single category named 'Other languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd51f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English                                  43415\n",
       "Arabic                                     894\n",
       "Spanish                                    632\n",
       "French                                     562\n",
       "German                                     501\n",
       "                                         ...  \n",
       "Iranian (Other)                              1\n",
       "Aromanian; Arumanian; Macedo-Romanian        1\n",
       "gu                                           1\n",
       "Faroese                                      1\n",
       "Afrikaans                                    1\n",
       "Name: language, Length: 92, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48147ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['English', 'Arabic', 'Spanish', 'French', 'German'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the unique values in the 'language' column\n",
    "language_counts = categorical['language'].value_counts()\n",
    "\n",
    "# Top 5 most common languages\n",
    "top_languages = language_counts.index[:5]\n",
    "top_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "308a7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the other languages with 'Other languages'\n",
    "categorical.loc[~categorical['language'].isin(top_languages), 'language'] = 'Other languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b139ad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'French', 'German', 'Other languages', 'Arabic',\n",
       "       'Spanish'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bc3360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical['language'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c8bdb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values\n",
    "# for col in categorical.columns:\n",
    "#    print(f\"Unique values for {col}: {categorical[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34080c",
   "metadata": {},
   "source": [
    "#### Concatenate numerical and categorical processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a74073ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_data_for_modelling = pd.concat([categorical,numerical],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94060b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>book_format</th>\n",
       "      <th>publisher</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>science fiction</th>\n",
       "      <th>dystopia</th>\n",
       "      <th>young adult</th>\n",
       "      <th>...</th>\n",
       "      <th>liked_perc</th>\n",
       "      <th>bbe_score</th>\n",
       "      <th>log_num_ratings</th>\n",
       "      <th>5_stars_num_ratings</th>\n",
       "      <th>1_star_num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>Unique Award (1)</th>\n",
       "      <th>Uncommon Award (2,3)</th>\n",
       "      <th>Singular Award (4-8)</th>\n",
       "      <th>Frequently Awarded Literary Prizes (9-15)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other series</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.476225</td>\n",
       "      <td>6.804602</td>\n",
       "      <td>3444695</td>\n",
       "      <td>93557</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 500 rated series</td>\n",
       "      <td>top_1000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>700-800</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.420324</td>\n",
       "      <td>6.399262</td>\n",
       "      <td>1593642</td>\n",
       "      <td>14526</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other series</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.355911</td>\n",
       "      <td>6.653316</td>\n",
       "      <td>2363896</td>\n",
       "      <td>80794</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 series                                author language  \\\n",
       "0          Other series  top_1001_to_10000_most_rated_authors  English   \n",
       "1  Top 500 rated series           top_1000_most_rated_authors  English   \n",
       "2          Other series  top_1001_to_10000_most_rated_authors  English   \n",
       "\n",
       "     pages book_format       publisher fantasy science fiction dystopia  \\\n",
       "0  200-300   Hardcover  Top Publishers       1               1        1   \n",
       "1  700-800   Paperback  Top Publishers       1               1        0   \n",
       "2  200-300   Paperback  Top Publishers       0               0        0   \n",
       "\n",
       "  young adult  ... liked_perc bbe_score log_num_ratings 5_stars_num_ratings  \\\n",
       "0           1  ...       96.0  6.476225        6.804602             3444695   \n",
       "1           1  ...       98.0  6.420324        6.399262             1593642   \n",
       "2           1  ...       95.0  6.355911        6.653316             2363896   \n",
       "\n",
       "  1_star_num_ratings rating Unique Award (1) Uncommon Award (2,3)  \\\n",
       "0              93557   4.33                4                    5   \n",
       "1              14526   4.50                2                    0   \n",
       "2              80794   4.28                0                    0   \n",
       "\n",
       "  Singular Award (4-8) Frequently Awarded Literary Prizes (9-15)  \n",
       "0                    3                                        15  \n",
       "1                    1                                         3  \n",
       "2                    0                                         2  \n",
       "\n",
       "[3 rows x 855 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(48655, 855)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(gr_data_for_modelling.head(3),gr_data_for_modelling.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37cfe8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN values\n",
    "gr_data_for_modelling.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdabae4",
   "metadata": {},
   "source": [
    "#### Saving data processed for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48798df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_data_for_modelling.to_csv('./2. Clean_df/gr_data_MODELLING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1296c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35807237",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8fd1db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a33c0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 855)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data = pd.read_csv('./2. Clean_df/gr_data_MODELLING.csv')\n",
    "gr_data = gr_data.drop(['Unnamed: 0'],axis=1)\n",
    "gr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3833fd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>language</th>\n",
       "      <th>pages</th>\n",
       "      <th>book_format</th>\n",
       "      <th>publisher</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>science fiction</th>\n",
       "      <th>dystopia</th>\n",
       "      <th>young adult</th>\n",
       "      <th>...</th>\n",
       "      <th>liked_perc</th>\n",
       "      <th>bbe_score</th>\n",
       "      <th>log_num_ratings</th>\n",
       "      <th>5_stars_num_ratings</th>\n",
       "      <th>1_star_num_ratings</th>\n",
       "      <th>rating</th>\n",
       "      <th>Unique Award (1)</th>\n",
       "      <th>Uncommon Award (2,3)</th>\n",
       "      <th>Singular Award (4-8)</th>\n",
       "      <th>Frequently Awarded Literary Prizes (9-15)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other series</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.476225</td>\n",
       "      <td>6.804602</td>\n",
       "      <td>3444695</td>\n",
       "      <td>93557</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top 500 rated series</td>\n",
       "      <td>top_1000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>700-800</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.420324</td>\n",
       "      <td>6.399262</td>\n",
       "      <td>1593642</td>\n",
       "      <td>14526</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other series</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>200-300</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.355911</td>\n",
       "      <td>6.653316</td>\n",
       "      <td>2363896</td>\n",
       "      <td>80794</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single Book</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>100-200</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>6.297348</td>\n",
       "      <td>6.476867</td>\n",
       "      <td>1617567</td>\n",
       "      <td>76770</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other series</td>\n",
       "      <td>top_1001_to_10000_most_rated_authors</td>\n",
       "      <td>English</td>\n",
       "      <td>400-500</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Top Publishers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.164189</td>\n",
       "      <td>6.695877</td>\n",
       "      <td>1751460</td>\n",
       "      <td>548674</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 series                                author language  \\\n",
       "0          Other series  top_1001_to_10000_most_rated_authors  English   \n",
       "1  Top 500 rated series           top_1000_most_rated_authors  English   \n",
       "2          Other series  top_1001_to_10000_most_rated_authors  English   \n",
       "3           Single Book  top_1001_to_10000_most_rated_authors  English   \n",
       "4          Other series  top_1001_to_10000_most_rated_authors  English   \n",
       "\n",
       "     pages book_format       publisher  fantasy  science fiction  dystopia  \\\n",
       "0  200-300   Hardcover  Top Publishers        1                1         1   \n",
       "1  700-800   Paperback  Top Publishers        1                1         0   \n",
       "2  200-300   Paperback  Top Publishers        0                0         0   \n",
       "3  100-200   Paperback  Top Publishers        0                0         0   \n",
       "4  400-500   Paperback  Top Publishers        1                1         0   \n",
       "\n",
       "   young adult  ...  liked_perc  bbe_score  log_num_ratings  \\\n",
       "0            1  ...        96.0   6.476225         6.804602   \n",
       "1            1  ...        98.0   6.420324         6.399262   \n",
       "2            1  ...        95.0   6.355911         6.653316   \n",
       "3            0  ...        94.0   6.297348         6.476867   \n",
       "4            1  ...        78.0   6.164189         6.695877   \n",
       "\n",
       "   5_stars_num_ratings  1_star_num_ratings  rating  Unique Award (1)  \\\n",
       "0              3444695               93557    4.33                 4   \n",
       "1              1593642               14526    4.50                 2   \n",
       "2              2363896               80794    4.28                 0   \n",
       "3              1617567               76770    4.26                 0   \n",
       "4              1751460              548674    3.60                 3   \n",
       "\n",
       "   Uncommon Award (2,3)  Singular Award (4-8)  \\\n",
       "0                     5                     3   \n",
       "1                     0                     1   \n",
       "2                     0                     0   \n",
       "3                     0                     0   \n",
       "4                     5                     4   \n",
       "\n",
       "   Frequently Awarded Literary Prizes (9-15)  \n",
       "0                                         15  \n",
       "1                                          3  \n",
       "2                                          2  \n",
       "3                                          0  \n",
       "4                                          6  \n",
       "\n",
       "[5 rows x 855 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a7025",
   "metadata": {},
   "source": [
    "#### X-y split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fc08abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target = 'rating'\n",
    "y = gr_data['rating']\n",
    "X = gr_data.drop(['rating'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deaa975",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a73eaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b449b",
   "metadata": {},
   "source": [
    "#### Split both Train and Test into numerical and categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d57c38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "X_train_num = X_train.select_dtypes(include=np.number)\n",
    "X_train_cat = X_train.select_dtypes(include=['object'])\n",
    "\n",
    "# X_test\n",
    "X_test_num = X_test.select_dtypes(include=np.number)\n",
    "X_test_cat = X_test.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312654e4",
   "metadata": {},
   "source": [
    "#### Numerical Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518bd00",
   "metadata": {},
   "source": [
    "- Fit only with numericals_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7074b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5390ad",
   "metadata": {},
   "source": [
    "- Transform both numericals_train and numericals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16d4fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "573dbcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train_num_scaled and X_test_num_scaled to dataframes\n",
    "X_train_num_scaled_df = pd.DataFrame(X_train_num_scaled, columns=X_train_num.columns)\n",
    "X_test_num_scaled_df = pd.DataFrame(X_test_num_scaled, columns=X_test_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b6e6e",
   "metadata": {},
   "source": [
    "#### Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd229ed",
   "metadata": {},
   "source": [
    "Fit only with categoricals_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26d48f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder().fit(X_train_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21e004",
   "metadata": {},
   "source": [
    "Encode both categoricals_train and numericals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "416deff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_encoded = encoder.transform(X_train_cat)\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c5b0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train_cat_encoded and X_test_cat_encoded to dataframes\n",
    "X_train_cat_encoded_df = pd.DataFrame(X_train_cat_encoded.toarray(), columns=encoder.get_feature_names_out())\n",
    "X_test_cat_encoded_df = pd.DataFrame(X_test_cat_encoded.toarray(), columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd06c1",
   "metadata": {},
   "source": [
    "#### Combine numericals_train and categoricals_train into train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5383a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = pd.concat([X_train_num_scaled_df, X_train_cat_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba552e",
   "metadata": {},
   "source": [
    "#### Combine numericals_test and categoricals_test into test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aec77f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = pd.concat([X_test_num_scaled_df, X_test_cat_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403524f",
   "metadata": {},
   "source": [
    "#### Define Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a65ffe",
   "metadata": {},
   "source": [
    "- Fit model on train_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52e4cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff32aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions on the training data: [3.73948669 4.16273499 3.79444885 4.09135437 3.90409851]\n",
      "\n",
      "R-squared score on the training data: 0.45\n",
      "Root mean squared error on the training data: 0.26\n",
      "Mean squared error on the training data: 0.07\n",
      "Mean absolute error on the training data: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training data\n",
    "y_train_pred = lr.predict(train_processed)\n",
    "\n",
    "print(\"First 5 predictions on the training data:\", y_train_pred[:5])\n",
    "\n",
    "# Evaluation metrics\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "mae = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"\\nR-squared score on the training data:\", round(r2, 2))\n",
    "print(\"Root mean squared error on the training data:\", round(rmse, 2))\n",
    "print(\"Mean squared error on the training data:\", round(mse, 2))\n",
    "print(\"Mean absolute error on the training data:\", round(mae, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817ed5d",
   "metadata": {},
   "source": [
    "#### Predictions on test_processed and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "883085c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data:\n",
      " 13219    4.05\n",
      "28726    4.00\n",
      "46900    3.86\n",
      "13985    4.51\n",
      "40148    4.10\n",
      "27223    3.97\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "Predictions on the TEST data: [4.00071716 4.00016785 3.89833069 4.48484802 3.92564392 3.77653503]\n",
      "\n",
      "R-squared score on the test data: 0.42\n",
      "Root mean squared error on the test data: 0.27\n",
      "Mean squared error on the test data: 0.07\n",
      "Mean absolute error on the test data: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test data\n",
    "y_test_pred = lr.predict(test_processed)\n",
    "\n",
    "print(\"Actual data:\\n\", y_test[:6])\n",
    "print(\"\\nPredictions on the TEST data:\", y_test_pred[:6])\n",
    "\n",
    "# Evaluation metrics on test data\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nR-squared score on the test data:\", round(r2_test, 2))\n",
    "print(\"Root mean squared error on the test data:\", round(rmse_test, 2))\n",
    "print(\"Mean squared error on the test data:\", round(mse_test, 2))\n",
    "print(\"Mean absolute error on the test data:\", round(mae_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e043deeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48655.000000\n",
       "mean         4.015514\n",
       "std          0.347446\n",
       "min          0.000000\n",
       "25%          3.820000\n",
       "50%          4.020000\n",
       "75%          4.220000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c583bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56042b0b",
   "metadata": {},
   "source": [
    "After trying to use 'genres' and 'awards' (binary values) features both as numerical or categorical, the model is not performing well on the test data in any case:\n",
    "\n",
    "An R-squared score of 0.42 indicates that the model explains 42% of the variance in the target variable.\n",
    "\n",
    "The root mean squared error (RMSE) on the test data is 0.27 ('rating' std = 0.34), which means that on average, the model's predictions are off by 0.27 units from the actual values.\n",
    "\n",
    "The mean squared error (MSE) on the test data is 0.07, which is the average squared difference between the predicted and actual values.\n",
    "\n",
    "The mean absolute error (MAE) on the test data is 0.17, which is the average absolute difference between the predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e5665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c553b1cf",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction: PCA and RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d6387",
   "metadata": {},
   "source": [
    "Considering that there are no large differences between the prediction scores of train and test data and variance of results for different subsets it's low, this model seems not to be overfitted. However, I'm going to check anyways if dimensionality reduction helps improving this scores.\n",
    "\n",
    "To do so, I'm going to apply PCA and RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bde6e4",
   "metadata": {},
   "source": [
    "- Principal Component Analysis PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e46c2",
   "metadata": {},
   "source": [
    "Despite the potential loss of interpretability (since the principal components are linear combinations of the original features) and that PCA assumes a linear relationship between the features and the target (which seems weak at the moment after the scores of my model), I'm going to use PCA as it can reveal patterns and relationships in the data that may not be apparent in the original feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b639472b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA on training data\n",
    "pca = PCA() #n_components=100\n",
    "pca.fit(train_processed)\n",
    "\n",
    "#pca.explained_variance_ratio_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af6f30ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the explained variance ratios\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "# Calculate the cumulative sum of variance explained\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "#cum_sum_eigenvalues\n",
    "\n",
    "# Plot the cumulative explained variance vs number of components\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, \n",
    "        alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, \n",
    "         where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6345a15",
   "metadata": {},
   "source": [
    "As shown in the graph, we can see that the features selected to predict the target variable have a very weak ability to capture the variance in the original data. Therefore, it may be difficult to improve the regression model just by reducing dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60c93a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48655, 855)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3f2f826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9011793924892567"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[:650].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83227f25",
   "metadata": {},
   "source": [
    "Number of dimensions: 650 (Variance explained 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8949aa6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.9)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=0.9)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit PCA on training data\n",
    "pca = PCA(0.90)\n",
    "pca.fit(train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "164fb982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and test data\n",
    "X_train_pca = pca.transform(train_processed)\n",
    "X_test_pca = pca.transform(test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d29be7",
   "metadata": {},
   "source": [
    "Linear Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "176469ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (PCA transformed): 0.3205262322266471\n"
     ]
    }
   ],
   "source": [
    "# Fit linear regression on transformed data\n",
    "lr_pca = LinearRegression().fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "print(\"R-squared score (PCA transformed):\", r2_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6a6aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(X_train_pca[:,0],X_train_pca[:,1], c = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc96941",
   "metadata": {},
   "source": [
    "The R2 score of the linear regression model decreased (-0.1)after applying PCA, indicating that the PCA transformation did not improve the model's ability to predict the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5689f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dc2a5de",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88ab3f",
   "metadata": {},
   "source": [
    "RFE helps to identify the most important features related to the target and it and can improve the accuracy of the model without sacrificing too much predictive power or information. As in each iteration removes the less ranked features in rfe.ranking_ I'm going to check if this type of reduction leads my regression model to better scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "476b4d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target metrics:\n",
      "count    48655.000000\n",
      "mean         4.015514\n",
      "std          0.347446\n",
      "min          0.000000\n",
      "25%          3.820000\n",
      "50%          4.020000\n",
      "75%          4.220000\n",
      "max          5.000000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 Score (Train)</th>\n",
       "      <th>R2 Score (Test)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_features_to_select</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.439327</td>\n",
       "      <td>0.421597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.442724</td>\n",
       "      <td>0.420984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.444348</td>\n",
       "      <td>0.421672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.445382</td>\n",
       "      <td>0.421402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.445978</td>\n",
       "      <td>0.421274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      R2 Score (Train)  R2 Score (Test)\n",
       "n_features_to_select                                   \n",
       "200                           0.439327         0.421597\n",
       "300                           0.442724         0.420984\n",
       "400                           0.444348         0.421672\n",
       "500                           0.445382         0.421402\n",
       "600                           0.445978         0.421274"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Range of values for n_features_to_select\n",
    "n_features_to_selects = range(200, 601, 100)\n",
    "\n",
    "# Empty list to store the results\n",
    "results = []\n",
    "\n",
    "for n_features_to_select in n_features_to_selects:\n",
    "    # RFE on the training set\n",
    "    lm_rfe = LinearRegression()\n",
    "    rfe = RFE(lm_rfe, n_features_to_select=n_features_to_select, verbose=False)\n",
    "    rfe.fit(train_processed, y_train)\n",
    "\n",
    "    # Top features from the test set\n",
    "    X_train_rfe = rfe.transform(train_processed)\n",
    "    X_test_rfe = rfe.transform(test_processed)\n",
    "\n",
    "    # Train the model on the selected features\n",
    "    lm_rfe.fit(X_train_rfe, y_train)\n",
    "\n",
    "    # predict the ratings for both training and test sets\n",
    "    y_train_pred = lm_rfe.predict(X_train_rfe)\n",
    "    y_test_pred = lm_rfe.predict(X_test_rfe)\n",
    "\n",
    "    # calculate the R2 score for both sets\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append((n_features_to_select, r2_train, r2_test))\n",
    "\n",
    "# New dataFrame to store the results\n",
    "df_results = pd.DataFrame(results, columns=['n_features_to_select', 'R2 Score (Train)', 'R2 Score (Test)'])\n",
    "df_results.set_index('n_features_to_select', inplace=True)\n",
    "\n",
    "# Get summary statistics of the 'rating' column\n",
    "rating_summary = gr_data['rating'].describe()\n",
    "\n",
    "# Format the summary statistics string\n",
    "summary_str = f\"Target metrics:\\n{rating_summary.to_string()}\"\n",
    "summary_str += \"\\n\\n\"\n",
    "\n",
    "# Print the results DataFrame and the summary statistics\n",
    "print(summary_str)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c1ec200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfe.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b767df",
   "metadata": {},
   "source": [
    "It seems like the RFE (Recursive Feature Elimination) approach was able to achieve a similar R2 score as the linear regression model, while only using 600 features compared to the original LR model's 855 features. This suggests that the RFE approach was able to identify the most important features for predicting the target variable and remove the irrelevant ones.\n",
    "\n",
    "On the other hand, the PCA approach performed much worse with an R2 score of -0.12, even though it operated with 650 features. This may indicate that PCA was not able to capture enough variance in the data and may have discarded important information during dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f989f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e89b7f4",
   "metadata": {},
   "source": [
    "## Alternative model: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7debb",
   "metadata": {},
   "source": [
    "As dimensionality reduction has not improved the scores of my linear regression model, I'm going to use a Random Forest Regressor (RFR) to predict the 'rating' and check if this model it's more sensitive to more complex relationships between the features and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9df05",
   "metadata": {},
   "source": [
    "Linear regression and random forest are two popular algorithms used in machine learning for regression tasks. Here are some pros and cons of each algorithm:\n",
    "\n",
    "Linear Regression:\n",
    "Pros:\n",
    "\n",
    "Simplicity: Linear regression is a simple and easy-to-understand algorithm, which makes it a good choice for simple problems.\n",
    "Speed: Linear regression is a fast algorithm that can handle large datasets with many features.\n",
    "Interpretability: The coefficients of a linear regression model can be easily interpreted as the effect of each feature on the target variable.\n",
    "Cons:\n",
    "\n",
    "Linearity assumption: Linear regression assumes that the relationship between the features and the target variable is linear, which may not be true in all cases.\n",
    "Sensitivity to outliers: Linear regression is sensitive to outliers, which can have a large effect on the estimated coefficients.\n",
    "Limited flexibility: Linear regression is limited to linear relationships, which may not capture complex relationships in the data.\n",
    "\n",
    "\n",
    "Random Forest:\n",
    "Pros:\n",
    "\n",
    "Non-linearity: Random forest can capture non-linear relationships between the features and the target variable.\n",
    "Robustness: Random forest is robust to outliers and noise in the data, since it averages the predictions of multiple trees.\n",
    "Flexibility: Random forest can handle a wide range of data types, including categorical and continuous variables.\n",
    "Cons:\n",
    "\n",
    "Complexity: Random forest can be a complex algorithm to understand and tune, especially when dealing with large datasets.\n",
    "Black-box model: Random forest can be difficult to interpret, since it involves multiple decision trees.\n",
    "Overfitting: Random forest can overfit the training data if the number of trees or the depth of the trees is too high.\n",
    "Overall, the choice between linear regression and random forest depends on the specific problem and data at hand. Linear regression is a good choice for simple problems with linear relationships, while random forest is more flexible and can handle more complex relationships, but may require more tuning and can be harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c015f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe6525a",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3fa2788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target metrics:\n",
      "count    48655.000000\n",
      "mean         4.015514\n",
      "std          0.347446\n",
      "min          0.000000\n",
      "25%          3.820000\n",
      "50%          4.020000\n",
      "75%          4.220000\n",
      "max          5.000000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.619288</td>\n",
       "      <td>0.216456</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.123997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.635481</td>\n",
       "      <td>0.211803</td>\n",
       "      <td>0.044860</td>\n",
       "      <td>0.117658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.636279</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.044762</td>\n",
       "      <td>0.117795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.634242</td>\n",
       "      <td>0.212163</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.117794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.634487</td>\n",
       "      <td>0.212092</td>\n",
       "      <td>0.044983</td>\n",
       "      <td>0.117712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.635357</td>\n",
       "      <td>0.211839</td>\n",
       "      <td>0.044876</td>\n",
       "      <td>0.117912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.635162</td>\n",
       "      <td>0.211896</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.117765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.635680</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.117746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.635956</td>\n",
       "      <td>0.211665</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.117772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.635109</td>\n",
       "      <td>0.211911</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.117619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           R2 Score      RMSE       MSE       MAE\n",
       "max_depth                                        \n",
       "5          0.619288  0.216456  0.046853  0.123997\n",
       "10         0.635481  0.211803  0.044860  0.117658\n",
       "15         0.636279  0.211571  0.044762  0.117795\n",
       "20         0.634242  0.212163  0.045013  0.117794\n",
       "25         0.634487  0.212092  0.044983  0.117712\n",
       "30         0.635357  0.211839  0.044876  0.117912\n",
       "35         0.635162  0.211896  0.044900  0.117765\n",
       "40         0.635680  0.211745  0.044836  0.117746\n",
       "45         0.635956  0.211665  0.044802  0.117772\n",
       "50         0.635109  0.211911  0.044906  0.117619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Range of values for max_depth\n",
    "max_depths = range(5, 51, 5)\n",
    "\n",
    "# Empty list to store the results\n",
    "results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    # Model\n",
    "    rf = RandomForestRegressor(max_depth=max_depth, min_samples_split=200, min_samples_leaf=200)\n",
    "    # Fit\n",
    "    rf.fit(train_processed, y_train)\n",
    "    # Predictions on the test data\n",
    "    y_pred = rf.predict(test_processed)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append((max_depth, r2, rmse, mse, mae))\n",
    "\n",
    "# New DataFrame to store the results\n",
    "df_results = pd.DataFrame(results, columns=['max_depth', 'R2 Score', 'RMSE', 'MSE', 'MAE'])\n",
    "df_results.set_index('max_depth', inplace=True)\n",
    "\n",
    "# Get summary statistics of the 'rating' column\n",
    "rating_summary = gr_data['rating'].describe()\n",
    "\n",
    "# Format the summary statistics string\n",
    "summary_str = f\"Target metrics:\\n{rating_summary.to_string()}\"\n",
    "summary_str += \"\\n\\n\"\n",
    "\n",
    "# Print the results DataFrame and the summary statistics\n",
    "print(summary_str)\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0baafad",
   "metadata": {},
   "source": [
    "The initial results of using RFR with a range of max_depth (5-50) show a significant improvement in the R2 score. The highest score achieved within this range was with max_depth = 15, which had a score of 0.636 (+0.21 compared to the LR model).\n",
    "\n",
    "Additionally, RFR outperforms LR in terms of RMSE (-0.06), MSE (-0.03), and MAE (-0.06).\n",
    "\n",
    "Next, I will explore the effect of larger max_depth values on the performance of the RFR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84369052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.211909</td>\n",
       "      <td>0.044905</td>\n",
       "      <td>0.117616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.635553</td>\n",
       "      <td>0.211782</td>\n",
       "      <td>0.044852</td>\n",
       "      <td>0.117948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.635504</td>\n",
       "      <td>0.211796</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>0.117730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.636942</td>\n",
       "      <td>0.211378</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.117684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.636564</td>\n",
       "      <td>0.211488</td>\n",
       "      <td>0.044727</td>\n",
       "      <td>0.117716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.635411</td>\n",
       "      <td>0.211823</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>0.117740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.635741</td>\n",
       "      <td>0.211727</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.117536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.211675</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.117607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0.636114</td>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.117649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.635224</td>\n",
       "      <td>0.211878</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>0.117734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           R2 Score      RMSE       MSE       MAE\n",
       "max_depth                                        \n",
       "50         0.635116  0.211909  0.044905  0.117616\n",
       "150        0.635553  0.211782  0.044852  0.117948\n",
       "250        0.635504  0.211796  0.044858  0.117730\n",
       "350        0.636942  0.211378  0.044681  0.117684\n",
       "450        0.636564  0.211488  0.044727  0.117716\n",
       "550        0.635411  0.211823  0.044869  0.117740\n",
       "650        0.635741  0.211727  0.044828  0.117536\n",
       "750        0.635922  0.211675  0.044806  0.117607\n",
       "850        0.636114  0.211619  0.044783  0.117649\n",
       "950        0.635224  0.211878  0.044892  0.117734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Target metrics: mean 4.015 / std 0.347 / min 0.00 / 25% 3.82 / 50% 4.02 / 75% 4.22 / max 5.00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Range of values for max_depth\n",
    "max_depths = range(50, 1001, 100)\n",
    "\n",
    "# Empty list to store the results\n",
    "results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    # Model\n",
    "    rf = RandomForestRegressor(max_depth=max_depth, min_samples_split=200, min_samples_leaf=200)\n",
    "    # Fit\n",
    "    rf.fit(train_processed, y_train)\n",
    "    # Predictions on the test data\n",
    "    y_pred = rf.predict(test_processed)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append((max_depth, r2, rmse, mse, mae))\n",
    "\n",
    "# New dataFrame to store the results\n",
    "df_results = pd.DataFrame(results, columns=['max_depth', 'R2 Score', 'RMSE', 'MSE', 'MAE'])\n",
    "df_results.set_index('max_depth', inplace=True)\n",
    "\n",
    "display(df_results)\n",
    "display(\"Target metrics: mean 4.015 / std 0.347 / min 0.00 / 25% 3.82 / 50% 4.02 / 75% 4.22 / max 5.00\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe7e67",
   "metadata": {},
   "source": [
    "Larger depths for RFR predictions have not achieved significant differences from previous ones. In this new range (50-950), the greatest R2 score for test predictions is max_depth=350, with a score only +0.0007 larger than the one obtained previously by max_depth=15. The other metrics also do not show any important differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0f2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d78e81",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f810d35",
   "metadata": {},
   "source": [
    "Amongst the typical features to assess literary books, my personal approach of using the great amount of unique genres and awards (listed in GoodReads dataset) as key predictors has not yield the expected results expected when applied to regression models.\n",
    "\n",
    "Although Random Forest Regressor (RFR) has achieved to explain the 63% of the variability in the target, which is moderately acceptable, it's still difficult to assess the non-linear and more complex relationship between these features and the 'rating'. A relationship that may not have been captured by the previous Linear Regression (LR).\n",
    "\n",
    "In fact, LR model only got an R2 score of 0.42, below the acceptable threshold, regardless of whether or not recursive feature elimination was applied. PCA got even worse results, yet it also provided evidence of the features' inadequate capacity to account for the variance.\n",
    "\n",
    "In summary, the use of so many features as predictors may not have facilitated the creation of a more robust regression model. Nonetheless, the RFR metrics indicate that this model is far from useless and has considerable room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c39d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
